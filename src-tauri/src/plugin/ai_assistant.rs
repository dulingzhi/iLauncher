// AI åŠ©æ‰‹æ’ä»¶ - æ”¯æŒ ChatGPT/Claude å¯¹è¯

use crate::core::types::*;
use crate::plugin::Plugin;
use anyhow::Result;
use async_trait::async_trait;
use fuzzy_matcher::skim::SkimMatcherV2;
use fuzzy_matcher::FuzzyMatcher;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AIConfig {
    pub provider: String, // "openai" or "anthropic"
    pub api_key: String,
    pub model: String,
    pub base_url: Option<String>,
    pub temperature: f32,
    pub max_tokens: usize,
}

impl Default for AIConfig {
    fn default() -> Self {
        Self {
            provider: "openai".to_string(),
            api_key: String::new(),
            model: "gpt-3.5-turbo".to_string(),
            base_url: None,
            temperature: 0.7,
            max_tokens: 2000,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatMessage {
    pub role: String, // system, user, assistant
    pub content: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Conversation {
    pub id: String,
    pub title: String,
    pub messages: Vec<ChatMessage>,
    pub timestamp: i64,
}

pub struct AIAssistantPlugin {
    metadata: PluginMetadata,
    config: Arc<RwLock<AIConfig>>,
    conversations: Arc<RwLock<Vec<Conversation>>>,
    current_conversation: Arc<RwLock<Option<String>>>, // current conversation ID
    client: Client,
    matcher: SkimMatcherV2,
}

impl AIAssistantPlugin {
    pub fn new() -> Self {
        Self {
            metadata: PluginMetadata {
                id: "ai_assistant".to_string(),
                name: "AI Assistant".to_string(),
                description: "Chat with AI (ChatGPT/Claude)".to_string(),
                author: "iLauncher".to_string(),
                version: "1.0.0".to_string(),
                icon: WoxImage::emoji("ğŸ¤–"),
                trigger_keywords: vec![
                    "ai".to_string(),
                    "gpt".to_string(),
                    "chat".to_string(),
                    "ask".to_string(),
                ],
                commands: vec![],
                settings: vec![
                    SettingDefinition {
                        r#type: "select".to_string(),
                        key: Some("provider".to_string()),
                        label: Some("AI Provider (openai/anthropic)".to_string()),
                        value: Some(serde_json::json!("openai")),
                    },
                    SettingDefinition {
                        r#type: "password".to_string(),
                        key: Some("api_key".to_string()),
                        label: Some("API Key (encrypted storage)".to_string()),
                        value: Some(serde_json::json!("")),
                    },
                    SettingDefinition {
                        r#type: "text".to_string(),
                        key: Some("model".to_string()),
                        label: Some("Model (e.g. gpt-3.5-turbo)".to_string()),
                        value: Some(serde_json::json!("gpt-3.5-turbo")),
                    },
                ],
                supported_os: vec![
                    "windows".to_string(),
                    "macos".to_string(),
                    "linux".to_string(),
                ],
                plugin_type: PluginType::Native,
            },
            config: Arc::new(RwLock::new(AIConfig::default())),
            conversations: Arc::new(RwLock::new(Vec::new())),
            current_conversation: Arc::new(RwLock::new(None)),
            client: Client::builder()
                .timeout(std::time::Duration::from_secs(60))
                .build()
                .unwrap(),
            matcher: SkimMatcherV2::default(),
        }
    }

    /// åŠ è½½é…ç½®
    pub async fn load_config(&self, config: AIConfig) {
        let mut cfg = self.config.write().await;
        *cfg = config;
        tracing::info!("AI Assistant config loaded: provider={}", cfg.provider);
    }

    /// è·å–é…ç½®
    pub async fn get_config(&self) -> AIConfig {
        self.config.read().await.clone()
    }

    /// åˆ›å»ºæ–°å¯¹è¯
    pub async fn create_conversation(&self, title: String) -> String {
        let conv = Conversation {
            id: uuid::Uuid::new_v4().to_string(),
            title,
            messages: vec![],
            timestamp: chrono::Local::now().timestamp(),
        };

        let id = conv.id.clone();
        let mut convs = self.conversations.write().await;
        convs.insert(0, conv);

        // è®¾ä¸ºå½“å‰å¯¹è¯
        let mut current = self.current_conversation.write().await;
        *current = Some(id.clone());

        tracing::info!("Created new conversation: {}", id);
        id
    }

    /// å‘é€æ¶ˆæ¯åˆ° AI
    pub async fn send_message(&self, message: String) -> Result<String> {
        let config = self.config.read().await.clone();

        if config.api_key.is_empty() {
            return Err(anyhow::anyhow!("API key not configured"));
        }

        // è·å–æˆ–åˆ›å»ºå½“å‰å¯¹è¯
        let conv_id = {
            let mut current = self.current_conversation.write().await;
            if current.is_none() {
                *current = Some(self.create_conversation("New Chat".to_string()).await);
            }
            current.clone().unwrap()
        };

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        {
            let mut convs = self.conversations.write().await;
            if let Some(conv) = convs.iter_mut().find(|c| c.id == conv_id) {
                conv.messages.push(ChatMessage {
                    role: "user".to_string(),
                    content: message.clone(),
                });
            }
        }

        // è°ƒç”¨ AI API
        let response = match config.provider.as_str() {
            "openai" => self.call_openai_api(&config, &conv_id).await?,
            "anthropic" => self.call_anthropic_api(&config, &conv_id).await?,
            _ => return Err(anyhow::anyhow!("Unknown provider: {}", config.provider)),
        };

        // æ·»åŠ  AI å“åº”
        {
            let mut convs = self.conversations.write().await;
            if let Some(conv) = convs.iter_mut().find(|c| c.id == conv_id) {
                conv.messages.push(ChatMessage {
                    role: "assistant".to_string(),
                    content: response.clone(),
                });

                // æ›´æ–°æ ‡é¢˜ï¼ˆä½¿ç”¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
                if conv.title == "New Chat" && !conv.messages.is_empty() {
                    conv.title = message[..message.len().min(30)].to_string();
                }
            }
        }

        Ok(response)
    }

    /// è°ƒç”¨ OpenAI API
    async fn call_openai_api(&self, config: &AIConfig, conv_id: &str) -> Result<String> {
        let base_url = config
            .base_url
            .clone()
            .unwrap_or_else(|| "https://api.openai.com/v1".to_string());

        // è·å–å¯¹è¯å†å²
        let messages = {
            let convs = self.conversations.read().await;
            convs
                .iter()
                .find(|c| c.id == conv_id)
                .map(|c| c.messages.clone())
                .unwrap_or_default()
        };

        #[derive(Serialize)]
        struct OpenAIRequest {
            model: String,
            messages: Vec<ChatMessage>,
            temperature: f32,
            max_tokens: usize,
        }

        #[derive(Deserialize)]
        struct OpenAIResponse {
            choices: Vec<OpenAIChoice>,
        }

        #[derive(Deserialize)]
        struct OpenAIChoice {
            message: ChatMessage,
        }

        let request = OpenAIRequest {
            model: config.model.clone(),
            messages,
            temperature: config.temperature,
            max_tokens: config.max_tokens,
        };

        let response = self
            .client
            .post(format!("{}/chat/completions", base_url))
            .header("Authorization", format!("Bearer {}", config.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(anyhow::anyhow!("OpenAI API error: {}", error_text));
        }

        let result: OpenAIResponse = response.json().await?;
        Ok(result
            .choices
            .first()
            .map(|c| c.message.content.clone())
            .unwrap_or_default())
    }

    /// è°ƒç”¨ Anthropic API (Claude)
    async fn call_anthropic_api(&self, config: &AIConfig, conv_id: &str) -> Result<String> {
        let base_url = config
            .base_url
            .clone()
            .unwrap_or_else(|| "https://api.anthropic.com/v1".to_string());

        // è·å–å¯¹è¯å†å²
        let messages = {
            let convs = self.conversations.read().await;
            convs
                .iter()
                .find(|c| c.id == conv_id)
                .map(|c| c.messages.clone())
                .unwrap_or_default()
        };

        #[derive(Serialize)]
        struct AnthropicRequest {
            model: String,
            messages: Vec<ChatMessage>,
            max_tokens: usize,
        }

        #[derive(Deserialize)]
        struct AnthropicResponse {
            content: Vec<AnthropicContent>,
        }

        #[derive(Deserialize)]
        struct AnthropicContent {
            text: String,
        }

        let request = AnthropicRequest {
            model: config.model.clone(),
            messages,
            max_tokens: config.max_tokens,
        };

        let response = self
            .client
            .post(format!("{}/messages", base_url))
            .header("x-api-key", &config.api_key)
            .header("anthropic-version", "2023-06-01")
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(anyhow::anyhow!("Anthropic API error: {}", error_text));
        }

        let result: AnthropicResponse = response.json().await?;
        Ok(result
            .content
            .first()
            .map(|c| c.text.clone())
            .unwrap_or_default())
    }

    /// è·å–å¯¹è¯åˆ—è¡¨
    pub async fn get_conversations(&self) -> Vec<Conversation> {
        self.conversations.read().await.clone()
    }

    /// åˆ‡æ¢å¯¹è¯
    pub async fn switch_conversation(&self, conv_id: String) {
        let mut current = self.current_conversation.write().await;
        *current = Some(conv_id);
    }

    /// åˆ é™¤å¯¹è¯
    pub async fn delete_conversation(&self, conv_id: String) {
        let mut convs = self.conversations.write().await;
        convs.retain(|c| c.id != conv_id);

        // å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰å¯¹è¯ï¼Œæ¸…ç©ºå½“å‰å¯¹è¯
        let mut current = self.current_conversation.write().await;
        if current.as_ref() == Some(&conv_id) {
            *current = None;
        }
    }
}

#[async_trait]
impl Plugin for AIAssistantPlugin {
    fn metadata(&self) -> &PluginMetadata {
        &self.metadata
    }

    async fn query(&self, ctx: &QueryContext) -> Result<Vec<QueryResult>> {
        let search = ctx.search.trim();

        // æ£€æŸ¥ API key é…ç½®
        let config = self.config.read().await;
        if config.api_key.is_empty() {
            return Ok(vec![QueryResult {
                id: "config".to_string(),
                title: "AI Assistant - Not Configured".to_string(),
                subtitle: "Click to configure API key in settings".to_string(),
                icon: WoxImage::emoji("âš™ï¸"),
                preview: None,
                score: 100,
                context_data: serde_json::Value::Null,
                group: Some("AI".to_string()),
                plugin_id: self.metadata.id.clone(),
                refreshable: false,
                actions: vec![Action {
                    id: "open_settings".to_string(),
                    name: "Open Settings".to_string(),
                    icon: None,
                    is_default: true,
                    prevent_hide: false,
                    hotkey: None,
                }],
            }]);
        }

        let mut results = Vec::new();

        // å¦‚æœæœ‰æœç´¢è¯ï¼Œæ˜¾ç¤º"è¯¢é—® AI"é€‰é¡¹
        if !search.is_empty() {
            results.push(QueryResult {
                id: "ask".to_string(),
                title: format!("Ask AI: {}", search),
                subtitle: format!("Send to {} {}", config.provider, config.model),
                icon: WoxImage::emoji("ğŸ’¬"),
                preview: None,
                score: 100,
                context_data: serde_json::to_value(search)?,
                group: Some("AI".to_string()),
                plugin_id: self.metadata.id.clone(),
                refreshable: false,
                actions: vec![Action {
                    id: "send".to_string(),
                    name: "Send Message".to_string(),
                    icon: None,
                    is_default: true,
                    prevent_hide: true, // ä¸éšè—çª—å£ï¼Œç­‰å¾…å“åº”
                    hotkey: None,
                }],
            });
        }

        // æ˜¾ç¤ºå¯¹è¯å†å²
        let conversations = self.conversations.read().await;
        for conv in conversations.iter().take(5) {
            let last_message = conv
                .messages
                .last()
                .map(|m| {
                    let preview = &m.content[..m.content.len().min(50)];
                    format!("{}: {}", m.role, preview)
                })
                .unwrap_or_else(|| "Empty conversation".to_string());

            let score = if search.is_empty() {
                90
            } else {
                self.matcher
                    .fuzzy_match(&conv.title, search)
                    .unwrap_or(0)
            };

            if score > 0 {
                results.push(QueryResult {
                    id: conv.id.clone(),
                    title: conv.title.clone(),
                    subtitle: last_message,
                    icon: WoxImage::emoji("ğŸ’­"),
                    preview: Some(Preview::Text(
                        conv.messages
                            .iter()
                            .map(|m| format!("{}: {}", m.role, m.content))
                            .collect::<Vec<_>>()
                            .join("\n\n"),
                    )),
                    score: score as i32,
                    context_data: serde_json::to_value(&conv.id)?,
                    group: Some("Conversations".to_string()),
                    plugin_id: self.metadata.id.clone(),
                    refreshable: false,
                    actions: vec![
                        Action {
                            id: "open".to_string(),
                            name: "Open Conversation".to_string(),
                            icon: None,
                            is_default: true,
                            prevent_hide: false,
                            hotkey: None,
                        },
                        Action {
                            id: "delete".to_string(),
                            name: "Delete".to_string(),
                            icon: None,
                            is_default: false,
                            prevent_hide: false,
                            hotkey: None,
                        },
                    ],
                });
            }
        }

        Ok(results)
    }

    async fn execute(&self, result_id: &str, action_id: &str) -> Result<()> {
        match action_id {
            "send" => {
                // å‘é€æ¶ˆæ¯ï¼ˆå®é™…å¤„ç†ç”±å‰ç«¯å®Œæˆï¼Œè¿™é‡Œåªæ˜¯å ä½ï¼‰
                tracing::info!("Sending message to AI: {}", result_id);
            }
            "open" => {
                // æ‰“å¼€å¯¹è¯
                self.switch_conversation(result_id.to_string()).await;
            }
            "delete" => {
                // åˆ é™¤å¯¹è¯
                self.delete_conversation(result_id.to_string()).await;
            }
            "open_settings" => {
                // æ‰“å¼€è®¾ç½®ï¼ˆç”±å‰ç«¯å¤„ç†ï¼‰
            }
            _ => {}
        }

        Ok(())
    }
}
